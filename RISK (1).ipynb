{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"pycharm":{"stem_cell":{"cell_type":"raw","source":[],"metadata":{"collapsed":false}}},"colab":{"name":"RISK.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"collapsed":true,"id":"Z4YwLKfNyNnK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"WDzCEGTbyNnL"},"source":["# Install packages not preinstalled in jupyter notebook (RUN ONCE)\n","\n","!pip install xgboost\n","!pip install seaborn\n","!pip install yellowbrick\n","!pip install category_encoders"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"oD6FARnFyNnM"},"source":["#import various libraries and toolkits\n","\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","from numpy import loadtxt\n","import xgboost as xgb\n","import matplotlib.pyplot as plt\n","import category_encoders as ce\n","import warnings\n","%matplotlib inline\n","\n","from sklearn.utils.multiclass import unique_labels\n","from xgboost.sklearn import XGBClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n","from sklearn.model_selection import train_test_split\n","from yellowbrick.classifier import ClassBalance, ROCAUC, ClassificationReport, ClassPredictionError\n","warnings.simplefilter('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"MjMN6WkQyNnN"},"source":["# function to plot confusion matrix (almost all of this was prebuilt. I made edits to fit my use-case)\n","\n","def plot_confusion_matrix(y_true, y_pred, classes,\n","                          normalize=False,\n","                          title=None,\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if not title:\n","        if normalize:\n","            title = 'Normalized confusion matrix'\n","        else:\n","            title = 'Confusion matrix, without normalization'\n","\n","    # Compute confusion matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","    # Only use the labels that appear in the data\n","    classes = classes[unique_labels(y_true, y_pred)]\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","    \n","    plt.figure(figsize=(20,10))\n","    fig, ax = plt.subplots()\n","    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n","    # We want to show all ticks...\n","    ax.set(xticks=np.arange(cm.shape[1]),\n","           yticks=np.arange(cm.shape[0]),\n","           # ... and label them with the respective list entries\n","           xticklabels=classes, yticklabels=classes,\n","           title=title,\n","           ylabel='Predicted label',\n","           xlabel='True label')\n","\n","    # Rotate the tick labels and set their alignment.\n","    \n","\n","    # Loop over data dimensions and create text annotations.\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            ax.text(j, i, format(cm[i, j], fmt),\n","                    ha=\"center\", va=\"center\",\n","                    color=\"white\" if cm[i, j] > thresh else \"black\")\n","    \n","    return ax"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"6Ai7YoIsyNnO"},"source":["PASS_NOpass_10k_0923.csv\n","2000 claims balanced.csv\n","BAC_118659_1108.csv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"RjOaZrKzyNnP"},"source":["trainset = input(\"What is the name of your training dataset?: \")\n","validationset = input('What is the name of your validation dataset?: ')\n","predictionset = input('What is the name of the prediction dataset?: ')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"yukHo-GRyNnP"},"source":["# Create function to read in testing dataset and predicting dataset\n","\n","def readinformattarget(trainset, predictionset):\n","    df = pd.read_csv(trainset, encoding = \"ISO-8859-1\")\n","    predictionset = pd.read_csv(predictionset, encoding = 'ISO-8859-1')\n","\n","    # Create list of df column names\n","    cols = list(df)\n","\n","    # Move 'Deviation Code F' to the front of the list of columns\n","    cols.insert(0, cols.pop(cols.index('Deviation Code F')))\n","    \n","    # Convert values of 'Deviation Code F' to 'non_compliant' or 'compliant' for vizualization purposes\n","    df.loc[(df['Deviation Code F'] != 'P'),'Deviation Code F']='Non-Compliant'\n","    df.loc[(df['Deviation Code F'] == 'P'),'Deviation Code F']='Compliant'\n","\n","    # Convert target variable to a category data type\n","    df['Deviation Code F'].astype('category')\n","    \n","    return df, predictionset\n","\n","# Assign training set and 'BAC to predict' to df and predictionset with intial formatting\n","df, predictionset = readinformattarget(trainset, predictionset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"wq3TyJTGyNnR"},"source":["# Create function to make a bar chart to examine distribution of deviation codes within the training set (WILL NOT BE IN PRODUCTION SCRIPT)\n","def targetdistributionviz(df):\n","    \n","    # formatting\n","    ax2 = sns.countplot(df['Deviation Code F'], label='Count').set_title('distribution of compliant and non-compliant claims')\n","    plt.xlabel('Target Column: Deviation Code F')\n","    ax2.figure.savefig('Pass_fail_count.png')\n","    \n","# Execute    \n","targetdistributionviz(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"cOKf_v7XyNnR"},"source":["# Create function to split the training set into X and y variables.\n","\n","def trainingsetsplit(trainfile):   \n","    # Re-initialize the training set as df for formatting purposes\n","    df = pd.read_csv(trainfile, encoding = \"ISO-8859-1\")\n","\n","    # Convert values of 'Deviation Code F' to 'non_compliant' or 'compliant' (0 or 1, respectively)\n","    df.loc[(df['Deviation Code F'] != 'P'),'Deviation Code F']='0'\n","    df.loc[(df['Deviation Code F'] == 'P'),'Deviation Code F']='1'\n","\n","    # Drop columns with duplicate names from our training dataset\n","    df = df.loc[:,~df.columns.duplicated()]\n","\n","    # Drop columns where all values are duplicates of another column\n","    df = df.T.drop_duplicates().T\n","\n","    # Drop columns where all values are the same\n","    nunique = df.apply(pd.Series.nunique)\n","    cols_to_drop = nunique[nunique == 1].index\n","    df.drop(cols_to_drop, axis=1)\n","\n","    # Split training set into feature set and response set\n","    X = df.drop('Deviation Code F',axis=1)\n","    y = df['Deviation Code F']\n","    y = y.to_frame()\n","    y = y.astype('int')\n","    return X, y\n","\n","X, y = trainingsetsplit(trainset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"BCkm9MagyNnT"},"source":["# Create running list of any columns that offer no statistical significance and drop them (will be updated as needed) (applying these drops to predictionset, because the final list of usable features must come from predictionset,\n","# as these are provided by our Audit Team partner, Cathy Snyder)\n","\n","predictionset = predictionset.drop(['CLAIM_NO', 'CLAIM_VERSION','Submitting_BAC'], axis = 1)\n","len(predictionset.dtypes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"Rh4O6cPXyNnU"},"source":["# Create a function to ensure that we are only using columns in our prediction set to train with\n","\n","def colmatching(original, predictionset, X):\n","    \n","    # create list of columns that exist in both data sets\n","    col_list = original.columns.intersection(predictionset.columns)\n","    \n","    # re-assign X and predictionset to account for list of similar columns\n","    X = X[col_list]\n","    predictionset = predictionset[col_list]\n","    return X, predictionset\n","\n","# Execute function\n","X, predictionset = colmatching(df, predictionset, X)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"HIq_rRsGyNnV"},"source":["# Recheck that both datasets have an identical number of columns\n","print(X.shape, predictionset.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"Bi-zLPaHyNnW"},"source":["# Examine column types for X to facilitate column conversion to their proper datatypes\n","\n","X.dtypes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"Od-eOUt4yNnW"},"source":["# Manual feature engineering. Converting columns to proper datatype for further processing\n","\n","cat_columns = ['Trouble_Code', 'Labor_Operation_cd', 'Model_Year', 'LABOR_OP_DEP_TYPE_KEY', 'REPAIR_GROUP_KEY', 'CUSTOMER_COMPLAINT_CD_KEY', 'FI_WARRANTY_TYPE_KEY']\n","int_columns = [ 'Odometer_Reading', 'TOTAL_LABOR_ITEM_COUNT', 'TOTAL_MATERIAL_QUANTITY', 'TOTAL_MESSAGE_COUNT_E']\n","float_columns = ['Net_Item_Amt_Exc_Tax', 'Total_Tax', 'Other_Hours', 'Total_Hours', 'TOTAL_DEDUCTIBLE_AMT', 'TOTAL_NET_ITEM_TAX_AMT', 'TOTAL_TAX_AMOUNT', 'TOTAL_LABOR_HOURS', 'OTHER_LABOR_HOURS', 'TOTAL_SUPP_LABOR_HOURS']\n","X[cat_columns] = X[cat_columns].astype('category')\n","X[int_columns] = X[int_columns].astype('int')\n","X[float_columns] = X[float_columns].astype('float')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"t8vNUHHFyNnW"},"source":["# Create function to perform hashing trick\n","\n","def hashingtrick(X):\n","    ce_hash = ce.HashingEncoder()\n","    hashed_X = ce_hash.fit_transform(X)\n","    return hashed_X\n","\n","# execute hashing trick and assign to hashed_X, then check datatypes for all columns for confirmation\n","hashed_X = hashingtrick(X)\n","hashed_X.dtypes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"q4IQRG7vyNnX"},"source":["# Process hashed_X and y through .Dmatrix function so xgboost can ingest the data\n","data_dmatrix = xgb.DMatrix(data = hashed_X, label = y)\n","\n","# Conduct another split (train/test split) in order to perform cross-validation techniques\n","X_train, X_test, y_train, y_test = train_test_split(hashed_X,y, test_size=0.25)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"xd593-D8yNnX"},"source":["X_train.dtypes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"b35Bpx-yyNnY"},"source":["# Instantiate process for Parameter tuning using cross validation\n","xgb_clf = xgb.XGBClassifier(tree_method = \"exact\", predictor = \"cpu_predictor\", verbosity = 1,\n","                            objective = \"binary:logistic\")\n","\n","# Create parameter grid\n","parameters = {\"learning_rate\": [0.1, 0.01, 0.001],\n","               \"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n","               \"max_depth\": [2, 4, 7, 10],\n","               \"colsample_bytree\": [0.3, 0.6, 0.8, 1.0],\n","               \"subsample\": [0.2, 0.4, 0.5, 0.6, 0.7], # I've recently read that a minimum of .8 is a best practice, but this is a new development. I've been afraid to change anything but was curious if you\n","                                                       # had any knowledge of this metric?\n","               \"reg_alpha\": [0, 0.5, 1],\n","               \"reg_lambda\": [1, 1.5, 2, 3, 4.5],\n","               \"min_child_weight\": [1, 3, 5, 7],\n","               \"n_estimators\": [100, 250, 500, 1000]}\n","\n","\n"],"execution_count":null,"outputs":[]}]}